{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNNSWh1MQSTi",
        "outputId": "99493d07-764f-4153-e02f-f84291b6a81e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:11<00:00, 226MB/s]\n",
            "100% 2.29G/2.29G [00:11<00:00, 220MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip chest-xray-pneumonia.zip &>/dev/null\n",
        "!pip install datasets &>/dev/null\n",
        "!pip install transformers &>/dev/null\n",
        "!pip install fastai &>/dev/null\n",
        "!pip install wandb &>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4650Xbh3U7F"
      },
      "outputs": [],
      "source": [
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 224\n",
        "def get_training_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "wOF-pUPi5lek",
        "outputId": "1206cfb4-5663-4612-ada6-cfc9c195a559"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from datasets import DatasetDict, Dataset\n",
        "from transformers import ViTFeatureExtractor, ViTImageProcessor\n",
        "from datasets import load_metric\n",
        "from torchvision.transforms import Compose, Normalize, RandomPerspective, ColorJitter, RandomHorizontalFlip\n",
        "import wandb; wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llZ_WIjV40oE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9908e9-0c35-433a-c454-aab58554b713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-59b9d7d64a00>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(data)\n"
          ]
        }
      ],
      "source": [
        "#train = get_training_data('chest_xray/chest_xray/train')\n",
        "test = get_training_data('chest_xray/chest_xray/test')\n",
        "val = get_training_data('chest_xray/chest_xray/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOXc5MZ_yUpe"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Projects/train.pt .\n",
        "train = torch.load('/content/drive/MyDrive/Projects/train.pt')\n",
        "train_labels = [int(_[1].item()) for _ in train]\n",
        "train = torch.load('/content/drive/MyDrive/Projects/train.pt')\n",
        "train_px_vals = [_[0] for _ in train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTSbqSZy4B4J"
      },
      "outputs": [],
      "source": [
        "def gray2color(gray_image):\n",
        "  gray_image = gray_image.unsqueeze(-1)\n",
        "  return torch.cat([gray_image, gray_image, gray_image], dim = -1)\n",
        "  #return gray_image.repeat(1, 1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wYBnIcUhisC"
      },
      "outputs": [],
      "source": [
        "train_data = {\n",
        "    'pixel_values': train_px_vals,\n",
        "    'label': train_labels\n",
        "}\n",
        "val_data = {\n",
        "    'pixel_values': [_ for _ in val[:, 0]],\n",
        "    'label': [_ for _ in val[:, 1]]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfcZI-uLCFWf"
      },
      "outputs": [],
      "source": [
        "train_dset = Dataset.from_dict(train_data)\n",
        "val_dset = Dataset.from_dict(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za7ggGcsaZCr"
      },
      "outputs": [],
      "source": [
        "del train_labels\n",
        "del train_px_vals\n",
        "del train_data\n",
        "del val_data\n",
        "del train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGfRrScdaQTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "337f0f4c66334948a08ea29735e32dc5",
            "842600bab1c64c2c82037f896747d4e1",
            "08ce7bfdf47a43f3a223bc4d7d807ec4",
            "8c93ba4763404a9cbcf43fe7b64acc84",
            "e1a89c9800674643a3d1b5d3b76550d5",
            "1676776eda1c420d91cbd54ede3cc732",
            "e85c480a15f3414a93f6575e98395064",
            "91ce683d414147aeac392cccc90baaca",
            "f6a6ac7eeb5646cd8a1fb3c0d67ef99d",
            "15f860ba4fe34ae28b726276d6cb0026",
            "e0ef8466b2ab422285455223bfe2f934"
          ]
        },
        "outputId": "28234db7-55fa-4962-afac-ee72e2bc1568"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "337f0f4c66334948a08ea29735e32dc5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224', do_resize = True)\n",
        "image_processor_2 = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224', do_resize = False)\n",
        "\n",
        "#feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224', do_resize = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPsyXopODVXp"
      },
      "outputs": [],
      "source": [
        "im = gray2color(torch.tensor(train_dset[9]['pixel_values']))\n",
        "#im_feat = feature_extractor(im, return_tensors = 'pt')['pixel_values'][0]\n",
        "im_proc = image_processor(im, return_tensors = 'pt')['pixel_values'][0]\n",
        "im_proc2 = image_processor_2(im, return_tensors = 'pt')['pixel_values'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHkWgnPfksUV"
      },
      "outputs": [],
      "source": [
        "def transforms(example):\n",
        "  processed_example = torch.tensor(example['pixel_values'])\n",
        "  processed_example = gray2color(processed_example)\n",
        "  processed_example = image_processor(processed_example, return_tensors = 'pt')\n",
        "  return {\n",
        "      'pixel_values': processed_example['pixel_values'],\n",
        "      'label': torch.tensor(example['label'])\n",
        "  }\n",
        "def test_transforms(example):\n",
        "  processed_example = torch.tensor(example['pixel_values']) /255.\n",
        "  processed_example = gray2color(processed_example)\n",
        "  processed_example = image_processor(processed_example, return_tensors = 'pt')\n",
        "  return {\n",
        "      'pixel_values': processed_example['pixel_values'],\n",
        "      'label': torch.tensor(example['label'])\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-vzpu7fk8lb"
      },
      "outputs": [],
      "source": [
        "train_dset = train_dset.with_transform(transforms)\n",
        "val_dset = val_dset.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHrR2aBfrihO"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiD235Nirx32"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  return {\n",
        "      'pixel_values': torch.stack([pixel_vals['pixel_values'] for pixel_vals in batch]),\n",
        "      'labels': torch.stack([pixel_vals['label'] for pixel_vals in batch])\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1AqGc7Auktl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "442b3774cc56470799940d5ca9690c65",
            "1278853f0d44458bbd9d525e4aca71a7",
            "3376633f8b94457f96ec9898bd7a60fe",
            "fce49131e8e54ce391f84a69ead3aa50",
            "bc9862a923cc490dbc79b3c60ad14f51",
            "2b9dd9f92af8452eb4c0ca0c636eb7ab",
            "9e6d15420cd74dffab40bd2ad82e7bb0",
            "6a13abb284a04ff0a721fbb36add6595",
            "6429eea0dab54e2ca9f13c5282d79700",
            "03ad9b6537444286bcd1bbd48747e625",
            "c122ca7b22eb4ec3b27e2ddcbc32bcf9"
          ]
        },
        "outputId": "0f5cf916-ea40-4410-dedd-d77d11a592c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-60bcc6e56918>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric('accuracy')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "442b3774cc56470799940d5ca9690c65"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "metric = load_metric('accuracy')\n",
        "def compute_metrics(p):\n",
        "  return metric.compute(\n",
        "      predictions = np.argmax(p.predictions, axis = 1),\n",
        "      references = p.label_ids\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGNuM5eavEHD"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './pneumonia_classifier',\n",
        "    per_device_train_batch_size = 16,\n",
        "    evaluation_strategy = 'steps',\n",
        "    num_train_epochs = 2,\n",
        "    save_steps = 200,\n",
        "    eval_steps = 200,\n",
        "    logging_steps = 20,\n",
        "    learning_rate = 2e-4,\n",
        "    save_total_limit = 2,\n",
        "    remove_unused_columns = False,\n",
        "    push_to_hub = False,\n",
        "    load_best_model_at_end = True,\n",
        "    report_to=\"wandb\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hvBkR2Yvrzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "e1a55282b91346628471414c244c4a05",
            "182b24b5111b499b8285ee05444b6287",
            "f8f8a476c049447ab34a925277950747",
            "aa525109f661475c8aec5fd9d9a86d7c",
            "1e9ddf38e2cf422a97d36720218b0871",
            "db89bbee800b417f904c56a0a069f476",
            "8a7192d62eb14739a30e1ee0dcf30b87",
            "cfd58d74115043ac97de55b19a416572",
            "7ab4f359938d41229240ba3aa1d9eaf2",
            "9a21deb5b7f147a4bd4ed1f86cec23df",
            "28c3f60935f44604a2791b6a17cae9a4",
            "8b3ecabc2dc04ec9a42d902575a49609",
            "c88bfd9d4cb04ed3bd392d59f9417adb",
            "d4d35ae68e2644918292a310c134f5da",
            "c6dc3f015ae3478e9772d8ff9a7396f4",
            "c40c76bd259e4816b945833f2d764ade",
            "d8d0e0d4cbd747acb33b0bd87f5aadd5",
            "c1b2ecef0d634c339270a8927070764d",
            "330ab57c405a440596919ce5185e35f0",
            "526ba53484c44258b5a85bb62181e02f",
            "619c176a94874cca91e687fe638a574c",
            "5f613bc206f248a683a5b90e86debf0c"
          ]
        },
        "outputId": "1855c1b7-e0f3-4325-e449-2308e4d27682"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1a55282b91346628471414c244c4a05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b3ecabc2dc04ec9a42d902575a49609"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224',\n",
        "    num_labels = len(labels),\n",
        "    ignore_mismatched_sizes = True\n",
        ")\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHcwDDABvtmv"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = collate_fn,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset = train_dset,\n",
        "    eval_dataset = val_dset,\n",
        "    tokenizer = image_processor\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19a95dcd3aaf4bf2ba2b1239b896cfc1",
            "e86de7b57d624e2a805303dbaa1c9bc6",
            "850b27f403ea4207b526c12701dd6a63",
            "a97e49c02be042fa8a692e89dfe987b0",
            "ba2cb72e894a470a984789dbe435c640",
            "5023264a26ff4c67977a6d34c8a8ba6f",
            "ac68b716020e4a10b1e7a2c91477e568",
            "081d95f774f347a3ba7c2c91891ca1ed"
          ]
        },
        "id": "Jczh7C9iwEd4",
        "outputId": "01ee39ac-c488-4cbf-aceb-7af6456281b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeedax\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230410_102825-8d21orsd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/deedax/huggingface/runs/8d21orsd' target=\"_blank\">true-donkey-23</a></strong> to <a href='https://wandb.ai/deedax/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/deedax/huggingface' target=\"_blank\">https://wandb.ai/deedax/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/deedax/huggingface/runs/8d21orsd' target=\"_blank\">https://wandb.ai/deedax/huggingface/runs/8d21orsd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='952' max='952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [952/952 18:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.539176</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.098100</td>\n",
              "      <td>0.521198</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.045300</td>\n",
              "      <td>0.008659</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =          2.0\n",
            "  total_flos               = 1099294038GF\n",
            "  train_loss               =       0.0695\n",
            "  train_runtime            =   0:18:24.97\n",
            "  train_samples_per_second =       13.785\n",
            "  train_steps_per_second   =        0.862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19a95dcd3aaf4bf2ba2b1239b896cfc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██</td></tr><tr><td>eval/loss</td><td>██▁▁</td></tr><tr><td>eval/runtime</td><td>▄▁█▁</td></tr><tr><td>eval/samples_per_second</td><td>▄█▁▇</td></tr><tr><td>eval/steps_per_second</td><td>▄█▁▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▅▃▃▆▂▂▃▃▁▁▂▁▁▁▂▂▁▁▁▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>1.0</td></tr><tr><td>eval/loss</td><td>0.00173</td></tr><tr><td>eval/runtime</td><td>0.6321</td></tr><tr><td>eval/samples_per_second</td><td>25.313</td></tr><tr><td>eval/steps_per_second</td><td>3.164</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>952</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0137</td></tr><tr><td>train/total_flos</td><td>1.1803579858094653e+18</td></tr><tr><td>train/train_loss</td><td>0.0695</td></tr><tr><td>train/train_runtime</td><td>1104.9709</td></tr><tr><td>train/train_samples_per_second</td><td>13.785</td></tr><tr><td>train/train_steps_per_second</td><td>0.862</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">true-donkey-23</strong> at: <a href='https://wandb.ai/deedax/huggingface/runs/8d21orsd' target=\"_blank\">https://wandb.ai/deedax/huggingface/runs/8d21orsd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230410_102825-8d21orsd/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_results = trainer.train()\n",
        "trainer.save_model()\n",
        "trainer.log_metrics('train', train_results.metrics)\n",
        "trainer.save_metrics('train', train_results.metrics)\n",
        "trainer.save_state()\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcwBecntxIbH"
      },
      "outputs": [],
      "source": [
        "test_data = {\n",
        "    'pixel_values': [_ for _ in test[:, 0]],\n",
        "    'label': [_ for _ in test[:, 1]]\n",
        "}\n",
        "test_dset = Dataset.from_dict(test_data)\n",
        "test_dset = test_dset.with_transform(test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "whGmFWsmdCzp",
        "outputId": "6068de30-8a7b-4672-90eb-393807620da6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230410_104712-svim0b98</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/deedax/uncategorized/runs/svim0b98' target=\"_blank\">solar-jazz-10</a></strong> to <a href='https://wandb.ai/deedax/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/deedax/uncategorized' target=\"_blank\">https://wandb.ai/deedax/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/deedax/uncategorized/runs/svim0b98' target=\"_blank\">https://wandb.ai/deedax/uncategorized/runs/svim0b98</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [78/78 00:28]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        2.0\n",
            "  eval_accuracy           =     0.8365\n",
            "  eval_loss               =      0.937\n",
            "  eval_runtime            = 0:00:29.12\n",
            "  eval_samples_per_second =     21.423\n",
            "  eval_steps_per_second   =      2.678\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83654</td></tr><tr><td>eval/loss</td><td>0.93699</td></tr><tr><td>eval/runtime</td><td>29.1272</td></tr><tr><td>eval/samples_per_second</td><td>21.423</td></tr><tr><td>eval/steps_per_second</td><td>2.678</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>952</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">solar-jazz-10</strong> at: <a href='https://wandb.ai/deedax/uncategorized/runs/svim0b98' target=\"_blank\">https://wandb.ai/deedax/uncategorized/runs/svim0b98</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230410_104712-svim0b98/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.init()\n",
        "metrics = trainer.evaluate(test_dset)\n",
        "trainer.log_metrics('eval', metrics)\n",
        "trainer.save_metrics('eval', metrics)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUtYbAHtxWBA",
        "outputId": "bbbbaee0-729a-4a85-8ad4-9bac09dd54e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Index:', 558, 'Predicted:', 0, 'Actual:', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import random\n",
        "idx = random.choice(range(624))\n",
        "with torch.no_grad():\n",
        "  logits = trainer.model(test_dset[idx]['pixel_values'][None, ...].to(device)).logits\n",
        "\"Index:\", idx, \"Predicted:\", logits.argmax().item(), \"Actual:\", test_dset[idx]['label'].item()"
      ]
    }
  ]
}